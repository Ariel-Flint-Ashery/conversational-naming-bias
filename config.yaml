network:
  network_type: 'complete'
  degree: 4
  alpha: 0.41
  beta: 0.54 
  erdos_p: 0.5
minority:
  minority_size_set: [0]
  committment_index: 1
params:
  temperature: 0.5
  runs: 6
  total_interactions: 5000 
  N: 24
  initial_set: ['None', 0.5, 0, 1]
  convergence_time: 72
  convergence_threshold: 0.95
  rewards_set: [[-50, 100]]
  memory_size_set: [5]
  options_set: 'stereo' # 'antistereo'
sim:
  version: 'swap'
  fill_blank: True
  continue_evolution: False
  consensus_evolution: False
  stochastic: True
  mode: 'api' #'gpu'
model:
  model_name: "meta-llama/Llama-3.3-70B-Instruct" 
  shorthand: "llama33_70B" 
  API_TOKEN: ''
  sys_prompt_is_avail: True
  chat_template_is_avail: True
  quantized: True